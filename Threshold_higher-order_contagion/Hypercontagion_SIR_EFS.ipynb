{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bd4fcbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "import itertools\n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import random\n",
    "import collections\n",
    "from time import time\n",
    "import xgi\n",
    "import math\n",
    "from tqdm import tqdm\n",
    "import pickle as pk\n",
    "\n",
    "def discrete_SIR(H,l,mu,theta,initial_infecteds=None,initial_recovereds=None,initial_number=1,tmin=0,tmax=float(\"Inf\"),dt=1.0):\n",
    "    #Simulates the discrete SIR model with threshold higher-order contagion on hypergraphs  \n",
    "    #H - xgi.Hypergraph - The hypergraph on which we simulate the SIR contagion process\n",
    "    #l - float - Infection probability of the model\n",
    "    #mu - float - Healing rate\n",
    "    #theta - float - Threshold for hyper-infection\n",
    "    #initial_infecteds - list - Initially infected node IDs.\n",
    "    #initial_recovereds -  list - Initially recovered node IDs.\n",
    "    #initial_number - int - Number of initially infected nodes.\n",
    "    #tmin - float - Time at which the simulation starts.\n",
    "    #tmax - float - Time at which the simulation terminates (if it doean't reach the absorbin state)\n",
    "    #dt - float - Time-step of the simulation.\n",
    "\n",
    "    if initial_infecteds is None:\n",
    "        initial_infecteds = random.sample(list(H.nodes), initial_number)\n",
    "\n",
    "    if initial_recovereds is None:\n",
    "        initial_recovereds = []\n",
    "\n",
    "    status = defaultdict(lambda: \"S\")\n",
    "    for node in initial_infecteds:\n",
    "        status[node] = \"I\"\n",
    "    for node in initial_recovereds:\n",
    "        status[node] = \"R\"\n",
    "    I = [len(initial_infecteds)]\n",
    "    R = [len(initial_recovereds)]\n",
    "    S = [H.num_nodes - I[0] - R[0]]\n",
    "    \n",
    "    times = [tmin]\n",
    "    t = tmin\n",
    "\n",
    "    new_status = status.copy()\n",
    "    \n",
    "    while t <= tmax and I[-1] != 0:\n",
    "        t += dt\n",
    "        \n",
    "        S.append(S[-1])\n",
    "        I.append(I[-1])\n",
    "        R.append(R[-1])\n",
    "        \n",
    "        i_edge={}\n",
    "        for edge_id in H.edges:\n",
    "            edge = H.edges.members(edge_id)\n",
    "            i_edge[edge_id]=0\n",
    "            idx_s=[]\n",
    "            for i in edge: #in each hyperedge estimate the number of I and the identitiy of nodes who are still S\n",
    "                if status[i]==\"I\":\n",
    "                    i_edge[edge_id]=i_edge[edge_id]+1\n",
    "                elif new_status[i]==\"S\": \n",
    "                    idx_s.append(i)\n",
    "            \n",
    "            if len(idx_s)>0 and (i_edge[edge_id]>=math.ceil(theta*len(edge))) and (random.random() <= l*dt): #conditions for group infection in the considered hyperedge (hihger-order threshold)\n",
    "                for i in idx_s:\n",
    "                    new_status[i]=\"I\" \n",
    "                I[-1] += len(idx_s)\n",
    "                S[-1] += -len(idx_s)\n",
    "                    \n",
    "        for node in H.nodes: #recovery\n",
    "            if status[node] == \"I\" and random.random() <= mu * dt:\n",
    "                new_status[node] = \"R\"\n",
    "                R[-1] += 1\n",
    "                I[-1] += -1\n",
    "        \n",
    "        times.append(t)\n",
    "        status = new_status.copy()        \n",
    "            \n",
    "    return np.array(times), np.array(S), np.array(I), np.array(R)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc594577",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataset='congress-bills_simplices';name_file='{0}'.format(dataset);\n",
    "#dataset='senate-bills_simplices';name_file='{0}'.format(dataset);\n",
    "#dataset='senate-committees_simplices';name_file='{0}'.format(dataset);\n",
    "#dataset='house-committees_simplices';name_file='{0}'.format(dataset);\n",
    "#dataset='email-Enron_simplices'; name_file='{0}'.format(dataset); \n",
    "#dataset='email-Eu_simplices'; name_file='{0}'.format(dataset); \n",
    "#dataset='hyperedges-cat-edge-algebra-questions_simplices'; name_file='{0}'.format(dataset);\n",
    "#dataset='hyperedges-cat-edge-geometry-questions_simplices'; name_file='{0}'.format(dataset);\n",
    "#dataset='hyperedges-cat-edge-music-blues-reviews'; name_file='{0}'.format(dataset);\n",
    "#dataset='Mid1'; name_file='aggr_15min_cliques_thr1_{0}'.format(dataset);\n",
    "#dataset='Elem1'; name_file='aggr_15min_cliques_thr1_{0}'.format(dataset);\n",
    "#dataset='InVS15'; name_file='aggr_15min_cliques_thr1_{0}'.format(dataset);\n",
    "#dataset='SFHH'; name_file='aggr_15min_cliques_thr1_{0}'.format(dataset);\n",
    "#dataset='LH10'; name_file='aggr_15min_cliques_thr1_{0}'.format(dataset);\n",
    "#dataset='LyonSchool'; name_file='aggr_15min_cliques_thr1_{0}'.format(dataset);\n",
    "#dataset='Thiers13'; name_file='aggr_15min_cliques_thr1_{0}'.format(dataset);\n",
    "#dataset='M_PL_015_ECO_ins';name_file='{0}'.format(dataset);\n",
    "#dataset='M_PL_062_ECO_ins';name_file='{0}'.format(dataset);\n",
    "#dataset='M_PL_015_ECO_pl';name_file='{0}'.format(dataset);\n",
    "#dataset='M_PL_015_ECO_pl';name_file='{0}'.format(dataset);\n",
    "\n",
    "with open('Data/{0}.json'.format(name_file)) as json_file:\n",
    "    data = json.load(json_file)\n",
    "    \n",
    "data = [data[i] for i in range(len(data)) if len(data[i])>1] #select only interactions of size >=2\n",
    "for i in range(len(data)): # sort each interaction with growing nodes' IDs (e.g. [2,1] -> [1,2])\n",
    "    data[i].sort()\n",
    "data.sort() # sort the interactions\n",
    "data = list(data for data,_ in itertools.groupby(data)) # remove interactions duplicated\n",
    "data.sort(key = len) # sort the interactions according to their length\n",
    "size_max=len(data[-1])\n",
    "\n",
    "H=xgi.Hypergraph(data)\n",
    "N=len(H.nodes)\n",
    "nodes=list(H.nodes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc53253c",
   "metadata": {},
   "source": [
    "## Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b79fa81",
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_infecteds=1\n",
    "mu=0.1\n",
    "n_runs = 300\n",
    "l=0.001\n",
    "theta=0.25\n",
    "\n",
    "output_path = '{0}_corr_EFS_seed_tetha{1}_l{2}_runs{3}_mu{4}.csv'.format(dataset,theta,l,n_runs,mu)\n",
    "\n",
    "f = open(output_path,'w')\n",
    "f.write('id_seed,run,EFS\\n')\n",
    "\n",
    "for seed_id in nodes:\n",
    "    for run_id in tqdm(range(n_runs)):\n",
    "        y=discrete_SIR(H,l,mu,theta,initial_infecteds=[seed_id],initial_recovereds=None,initial_number=initial_infecteds,tmin=0,tmax=float(1e2),dt=1.0)\n",
    "                \n",
    "        line = \"%i,%i,%i\\n\"%(seed_id,run_id,y[3][-1])\n",
    "        f.write(line)\n",
    "        \n",
    "f.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
