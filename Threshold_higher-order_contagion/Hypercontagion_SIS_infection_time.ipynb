{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bd4fcbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "import itertools\n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import random\n",
    "import collections\n",
    "from time import time\n",
    "import xgi\n",
    "import math\n",
    "from tqdm import tqdm\n",
    "import pickle as pk\n",
    "\n",
    "def discrete_SIS(H,l,mu,dt_inf,run_id,theta,initial_number=1,tmin=0,tmax=float(\"Inf\"),dt=1.0):\n",
    "    #Simulates the discrete SIS model with threshold higher-order contagion on hypergraphs  \n",
    "    #H - xgi.Hypergraph - The hypergraph on which we simulate the SIS contagion process\n",
    "    #l - float - Infection probability of the model\n",
    "    #mu - float - Healing rate\n",
    "    #dt_inf - dictionary - keys are nodes' IDs, values are array where the time passed infected will be stored for each run\n",
    "    #run_id - integer - ID of the actual realization of the simulation\n",
    "    #theta - float - Threshold for hyper-infection\n",
    "    #initial_number - int - Number of initially infected nodes\n",
    "    #tmin - float - Time at which the simulation starts.\n",
    "    #tmax - float - Time at which the simulation terminates (if it doean't reach the absorbin state)\n",
    "    #dt - float - Time-step of the simulation.\n",
    "\n",
    "    initial_infecteds = random.sample(list(H.nodes), initial_number)\n",
    "\n",
    "    status = defaultdict(lambda: \"S\")\n",
    "   \n",
    "    for node in initial_infecteds:\n",
    "        status[node] = \"I\"\n",
    "\n",
    "    I = [len(initial_infecteds)]\n",
    "    S = [H.num_nodes - I[0]]\n",
    "    \n",
    "    times = [tmin]\n",
    "    t = tmin\n",
    "    t_last_inf={}\n",
    "\n",
    "    new_status = status.copy()\n",
    "    \n",
    "    det_act=0\n",
    "    t_wait=100\n",
    "    k_tstep=10\n",
    "    \n",
    "    T=tmax\n",
    "    \n",
    "    inf_new=[]\n",
    "    inf_size=[]\n",
    "    \n",
    "    while t <= T:\n",
    "        t += dt\n",
    "        \n",
    "        if det_act==0 and t>t_wait and np.max(np.abs(I[len(I)-k_tstep:len(I)]-np.mean(I[len(I)-k_tstep:len(I)])))<0.05*N: # the infection time is stored only when the system reach the steady state\n",
    "            T=tmax+t\n",
    "            det_act=1\n",
    "            for node in H.nodes:\n",
    "                if status[node] == \"I\":\n",
    "                    t_last_inf[node]=t                    \n",
    "        \n",
    "        if I[-1]==0:\n",
    "            initial_infecteds = random.sample(list(H.nodes), 1)\n",
    "            status[initial_infecteds[0]] = \"I\"\n",
    "            new_status = status.copy()\n",
    "            I.append(len(initial_infecteds))\n",
    "            S.append(H.num_nodes - 1)   \n",
    "            if det_act==1:\n",
    "                t_last_inf[initial_infecteds[0]]=t-dt\n",
    "        else:      \n",
    "            S.append(S[-1])\n",
    "            I.append(I[-1])\n",
    "        \n",
    "        i_edge={}\n",
    "        for edge_id in H.edges:\n",
    "            edge = H.edges.members(edge_id)\n",
    "            i_edge[edge_id]=0\n",
    "            idx_s=[]\n",
    "            for i in edge: #in each hyperedge estimate the number of I and the identitiy of nodes who are still S\n",
    "                if status[i]==\"I\":\n",
    "                    i_edge[edge_id]=i_edge[edge_id]+1\n",
    "                elif new_status[i]==\"S\":\n",
    "                    idx_s.append(i)\n",
    "            \n",
    "            if len(idx_s)>0 and (i_edge[edge_id]>=math.ceil(theta*len(edge))) and (random.random() <= l*dt): #conditions for group infection in the considered hyperedge (hihger-order threshold)\n",
    "                for i in idx_s:\n",
    "                    new_status[i]=\"I\"\n",
    "                    if det_act==1:\n",
    "                        t_last_inf[i]=t\n",
    "                        inf_size.append(len(edge))\n",
    "                        inf_new.append(len(idx_s))\n",
    "                I[-1] += len(idx_s)\n",
    "                S[-1] += -len(idx_s)\n",
    "                    \n",
    "        for node in H.nodes:\n",
    "            if status[node] == \"I\" and random.random() <= mu * dt: #recovery\n",
    "                new_status[node] = \"S\"\n",
    "                I[-1] += -1\n",
    "                S[-1] += 1\n",
    "                if det_act==1:\n",
    "                    dt_inf[node][run_id]=dt_inf[node][run_id]+(t-t_last_inf[node])\n",
    "        \n",
    "        times.append(t)\n",
    "        status = new_status.copy()        \n",
    "    \n",
    "    return np.array(times), np.array(S), np.array(I), inf_new, inf_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc594577",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset='congress-bills_simplices';name_file='{0}'.format(dataset);\n",
    "#dataset='senate-bills_simplices';name_file='{0}'.format(dataset);\n",
    "#dataset='senate-committees_simplices';name_file='{0}'.format(dataset);\n",
    "#dataset='house-committees_simplices';name_file='{0}'.format(dataset);\n",
    "#dataset='email-Enron_simplices'; name_file='{0}'.format(dataset); \n",
    "#dataset='email-Eu_simplices'; name_file='{0}'.format(dataset); \n",
    "#dataset='hyperedges-cat-edge-algebra-questions_simplices'; name_file='{0}'.format(dataset);\n",
    "#dataset='hyperedges-cat-edge-geometry-questions_simplices'; name_file='{0}'.format(dataset);\n",
    "#dataset='hyperedges-cat-edge-music-blues-reviews'; name_file='{0}'.format(dataset);\n",
    "#dataset='Mid1'; name_file='aggr_15min_cliques_thr1_{0}'.format(dataset);\n",
    "#dataset='Elem1'; name_file='aggr_15min_cliques_thr1_{0}'.format(dataset);\n",
    "#dataset='InVS15'; name_file='aggr_15min_cliques_thr1_{0}'.format(dataset);\n",
    "#dataset='SFHH'; name_file='aggr_15min_cliques_thr1_{0}'.format(dataset);\n",
    "#dataset='LH10'; name_file='aggr_15min_cliques_thr1_{0}'.format(dataset);\n",
    "#dataset='LyonSchool'; name_file='aggr_15min_cliques_thr1_{0}'.format(dataset);\n",
    "#dataset='Thiers13'; name_file='aggr_15min_cliques_thr1_{0}'.format(dataset);\n",
    "#dataset='M_PL_015_ECO_ins';name_file='{0}'.format(dataset);\n",
    "#dataset='M_PL_062_ECO_ins';name_file='{0}'.format(dataset);\n",
    "#dataset='M_PL_015_ECO_pl';name_file='{0}'.format(dataset);\n",
    "#dataset='M_PL_015_ECO_pl';name_file='{0}'.format(dataset);\n",
    "\n",
    "with open('Data/{0}.json'.format(name_file)) as json_file:\n",
    "    data = json.load(json_file)\n",
    "    \n",
    "data = [data[i] for i in range(len(data)) if len(data[i])>1] #select only interactions of size >=2\n",
    "for i in range(len(data)): # sort each interaction with growing nodes' IDs (e.g. [2,1] -> [1,2])\n",
    "    data[i].sort()\n",
    "data.sort() # sort the interactions\n",
    "data = list(data for data,_ in itertools.groupby(data)) # remove interactions duplicated\n",
    "data.sort(key = len) # sort the interactions according to their length\n",
    "size_max=len(data[-1])\n",
    "\n",
    "H=xgi.Hypergraph(data)\n",
    "N=len(H.nodes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc53253c",
   "metadata": {},
   "source": [
    "## Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b79fa81",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "mu=0.1\n",
    "n_runs = 1000\n",
    "l=0.005\n",
    "theta=0.5\n",
    "tmax=float(1e3)\n",
    "\n",
    "dt_inf={}\n",
    "for i in H.nodes:\n",
    "    dt_inf[i]=np.zeros(n_runs)\n",
    "\n",
    "for run_id in tqdm(range(n_runs)):         \n",
    "    y=discrete_SIS(H,l,mu,dt_inf,run_id,theta,initial_number=1,tmin=0,tmax=tmax,dt=1.0)\n",
    "   \n",
    "    for i in H.nodes:\n",
    "        dt_inf[i][run_id]=dt_inf[i][run_id]/tmax\n",
    "\n",
    "pk.dump(dt_inf, open('dt_inf_dict_{0}_theta{1}_lambda{2}_mu{3}.pck'.format(dataset,theta,l,mu),'wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
