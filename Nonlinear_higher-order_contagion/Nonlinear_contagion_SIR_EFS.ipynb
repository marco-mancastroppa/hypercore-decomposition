{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bd4fcbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "import itertools\n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import random\n",
    "import collections\n",
    "from time import time\n",
    "import xgi\n",
    "from tqdm import tqdm\n",
    "import pickle as pk\n",
    "        \n",
    "def discrete_SIR(H,l,mu,nu,prob_inf_edge,initial_infecteds=None,initial_recovereds=None,initial_number=1,tmin=0,tmax=float(\"Inf\"),dt=1.0):\n",
    "    #Simulates the discrete SIR model with nonlinear contagion on hypergraphs  \n",
    "    #H - xgi.Hypergraph - The hypergraph on which we simulate the SIR contagion process\n",
    "    #l - float -Infection probability of the model\n",
    "    #mu - float - Healing rate\n",
    "    #nu - float - Exponent of the non-linear infection term\n",
    "    #prob_inf_edge - list - Each element in position m gives the probability that a susceptible node is NOT infected if in a group with m infected\n",
    "    #initial_infecteds - list - Initially infected node IDs.\n",
    "    #initial_recovereds - list - Initially recovered node IDs.\n",
    "    #initial_number - int - Number of initially infected nodes.\n",
    "    #tmin - float - Time at which the simulation starts.\n",
    "    #tmax - float - Time at which the simulation terminates (if it doean't reach the absorbing state)\n",
    "    #dt - float - Time-step of the simulation.\n",
    "    \n",
    "    if initial_infecteds is None:\n",
    "        initial_infecteds = random.sample(list(H.nodes), initial_number) #random select initial infected nodes\n",
    "\n",
    "    if initial_recovereds is None:\n",
    "        initial_recovereds = []\n",
    "\n",
    "    status = defaultdict(lambda: \"S\")\n",
    "    for node in initial_infecteds:\n",
    "        status[node] = \"I\"\n",
    "    for node in initial_recovereds:\n",
    "        status[node] = \"R\"\n",
    "    I = [len(initial_infecteds)]\n",
    "    R = [len(initial_recovereds)]\n",
    "    S = [H.num_nodes - I[0] - R[0]]\n",
    "    \n",
    "    times = [tmin]\n",
    "    t = tmin\n",
    "\n",
    "    new_status = status.copy()\n",
    "\n",
    "    while t <= tmax and I[-1] != 0: \n",
    "        t += dt\n",
    "        \n",
    "        S.append(S[-1])\n",
    "        I.append(I[-1])\n",
    "        R.append(R[-1])\n",
    "        \n",
    "        i_edge={}\n",
    "        for edge_id in H.edges:\n",
    "            edge = H.edges.members(edge_id)\n",
    "            i_edge[edge_id]=0\n",
    "            for i in edge:\n",
    "                if status[i]==\"I\":\n",
    "                    i_edge[edge_id]=i_edge[edge_id]+1 #for each hyperedge update the number of infected within it\n",
    "                    \n",
    "        for node in H.nodes:\n",
    "            if status[node] == \"I\" and random.random() <= mu * dt: #recovery\n",
    "                new_status[node] = \"R\"\n",
    "                R[-1] += 1\n",
    "                I[-1] += -1\n",
    "            elif status[node] == \"S\":\n",
    "                p=1\n",
    "                for edge_id in H.nodes.memberships(node): #infection from all the possible hyperedges\n",
    "                    p=p*prob_inf_edge[i_edge[edge_id]]\n",
    "                if random.random() <= (1-p) * dt:\n",
    "                    new_status[node] = \"I\"\n",
    "                    S[-1] += -1\n",
    "                    I[-1] += 1\n",
    "               \n",
    "        status = new_status.copy()\n",
    "        times.append(t)\n",
    "    \n",
    "    return np.array(times), np.array(S), np.array(I), np.array(R)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc594577",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset='congress-bills_simplices';name_file='{0}'.format(dataset);\n",
    "#dataset='senate-bills_simplices';name_file='{0}'.format(dataset);\n",
    "#dataset='senate-committees_simplices';name_file='{0}'.format(dataset);\n",
    "#dataset='house-committees_simplices';name_file='{0}'.format(dataset);\n",
    "#dataset='email-Enron_simplices'; name_file='{0}'.format(dataset); \n",
    "#dataset='email-Eu_simplices'; name_file='{0}'.format(dataset); \n",
    "#dataset='hyperedges-cat-edge-algebra-questions_simplices'; name_file='{0}'.format(dataset);\n",
    "#dataset='hyperedges-cat-edge-geometry-questions_simplices'; name_file='{0}'.format(dataset);\n",
    "#dataset='hyperedges-cat-edge-music-blues-reviews'; name_file='{0}'.format(dataset);\n",
    "#dataset='Mid1'; name_file='aggr_15min_cliques_thr1_{0}'.format(dataset);\n",
    "#dataset='Elem1'; name_file='aggr_15min_cliques_thr1_{0}'.format(dataset);\n",
    "#dataset='InVS15'; name_file='aggr_15min_cliques_thr1_{0}'.format(dataset);\n",
    "#dataset='SFHH'; name_file='aggr_15min_cliques_thr1_{0}'.format(dataset);\n",
    "#dataset='LH10'; name_file='aggr_15min_cliques_thr1_{0}'.format(dataset);\n",
    "#dataset='LyonSchool'; name_file='aggr_15min_cliques_thr1_{0}'.format(dataset);\n",
    "#dataset='Thiers13'; name_file='aggr_15min_cliques_thr1_{0}'.format(dataset);\n",
    "#dataset='M_PL_015_ECO_ins';name_file='{0}'.format(dataset);\n",
    "#dataset='M_PL_062_ECO_ins';name_file='{0}'.format(dataset);\n",
    "#dataset='M_PL_015_ECO_pl';name_file='{0}'.format(dataset);\n",
    "#dataset='M_PL_015_ECO_pl';name_file='{0}'.format(dataset);\n",
    "\n",
    "with open('Data/{0}.json'.format(name_file)) as json_file:\n",
    "    data = json.load(json_file)\n",
    "    \n",
    "data = [data[i] for i in range(len(data)) if len(data[i])>1] #consider only interactions of size >=2\n",
    "for i in range(len(data)): # sort each interaction with growing nodes' IDs (e.g. [2,1] -> [1,2])\n",
    "    data[i].sort()\n",
    "data.sort() # sort the interactions\n",
    "data = list(data for data,_ in itertools.groupby(data)) # remove interactions duplicated\n",
    "data.sort(key = len) # sort the interactions according to their length\n",
    "size_max=len(data[-1])\n",
    "\n",
    "H=xgi.Hypergraph(data)\n",
    "N=len(H.nodes)\n",
    "nodes=list(H.nodes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00aae5be",
   "metadata": {},
   "source": [
    "## Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b79fa81",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "mu=0.1\n",
    "nu=4\n",
    "l=0.001\n",
    "initial_infecteds=1\n",
    "n_runs=300\n",
    "\n",
    "prob_inf_edge=[np.exp(-l*i**nu) for i in range(0,size_max)] #Each element in position m gives the probability that a susceptible node is NOT infected if in a group with m infected\n",
    "\n",
    "output_path = '{0}_corr_EFS_seed_nu{1}_l{2}_runs{3}_mu{4}.csv'.format(dataset,nu,l,n_runs,mu)\n",
    "\n",
    "f = open(output_path,'w')\n",
    "f.write('id_seed,run,EFS\\n')\n",
    "\n",
    "for seed_id in nodes:\n",
    "    for run_id in tqdm(range(n_runs)):\n",
    "        y=discrete_SIR(H,l,mu,nu,prob_inf_edge,initial_infecteds=[seed_id],initial_recovereds=None,initial_number=initial_infecteds,tmin=0,tmax=float(1e2),dt=1.0)\n",
    "        \n",
    "        line = \"%i,%i,%i\\n\"%(seed_id,run_id,y[3][-1])\n",
    "        f.write(line)\n",
    "f.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
